{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-31T11:22:27.809733Z",
     "start_time": "2024-10-31T11:22:27.485984Z"
    }
   },
   "id": "8b2a423c1d510bc2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Specify the input and output folders\n",
    "input_folder = 'data'\n",
    "output_folder = 'data_reduced'\n",
    "\n",
    "# Ensure the output folder exists\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Define the columns to keep\n",
    "columns_to_extract = [\n",
    "    \"location_key\", \"date\", \"wikidata_id\", \"country_name\", \"new_confirmed\", \n",
    "    \"new_deceased\", \"population\", \"latitude\", \"longitude\", \"school_closing\", \n",
    "    \"workplace_closing\", \"cancel_public_events\", \"restrictions_on_gatherings\", \n",
    "    \"public_transport_closing\", \"stay_at_home_requirements\", \n",
    "    \"restrictions_on_internal_movement\", \"international_travel_controls\", \n",
    "    \"contact_tracing\", \"stringency_index\"\n",
    "]\n",
    "\n",
    "# Loop through all files in the input folder\n",
    "for filename in os.listdir(input_folder):\n",
    "    # Check if the file is a CSV\n",
    "    if filename.endswith('.csv'):\n",
    "        file_path = os.path.join(input_folder, filename)\n",
    "        \n",
    "        # Load the file into a DataFrame\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        # Identify missing columns\n",
    "        missing_columns = [col for col in columns_to_extract if col not in df.columns]\n",
    "        \n",
    "        # Add missing columns with zeros\n",
    "        for col in missing_columns:\n",
    "            df[col] = 0\n",
    "        \n",
    "        # Extract and reorder the specified columns\n",
    "        df_reduced = df[columns_to_extract]\n",
    "        \n",
    "        # Save the reduced DataFrame to the output folder\n",
    "        output_path = os.path.join(output_folder, filename)\n",
    "        df_reduced.to_csv(output_path, index=False)\n",
    "        \n",
    "        print(f'Saved reduced data for {filename} to {output_path}')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "initial_id"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Specify the input and output folders\n",
    "input_folder = 'data_reduced'          # Load from reduced daily data\n",
    "output_folder = 'data_reduced_weekly'  # Save to weekly data folder\n",
    "\n",
    "# Ensure the output folder exists\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Define columns and their aggregation rules\n",
    "aggregation_functions = {\n",
    "    \"location_key\": \"first\",\n",
    "    \"wikidata_id\": \"first\",\n",
    "    \"country_name\": \"first\",\n",
    "    \"population\": \"first\",\n",
    "    \"latitude\": \"first\",\n",
    "    \"longitude\": \"first\",\n",
    "    \"school_closing\": \"max\",\n",
    "    \"workplace_closing\": \"max\",\n",
    "    \"cancel_public_events\": \"max\",\n",
    "    \"restrictions_on_gatherings\": \"max\",\n",
    "    \"public_transport_closing\": \"max\",\n",
    "    \"stay_at_home_requirements\": \"max\",\n",
    "    \"restrictions_on_internal_movement\": \"max\",\n",
    "    \"international_travel_controls\": \"max\",\n",
    "    \"contact_tracing\": \"max\",\n",
    "    \"stringency_index\": \"max\",\n",
    "    \"new_confirmed\": \"sum\",\n",
    "    \"new_deceased\": \"sum\"\n",
    "}\n",
    "\n",
    "# Loop through all files in the input folder\n",
    "for filename in os.listdir(input_folder):\n",
    "    if filename.endswith('.csv'):\n",
    "        file_path = os.path.join(input_folder, filename)\n",
    "        \n",
    "        # Load the reduced daily data file\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        # Ensure the date column is in datetime format\n",
    "        df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "        \n",
    "        # Set date as the index for resampling\n",
    "        df.set_index('date', inplace=True)\n",
    "        \n",
    "        # Resample the data to weekly frequency starting on Thursday and apply custom aggregation\n",
    "        df_weekly = df.resample('W-THU').apply(aggregation_functions)\n",
    "        \n",
    "        # Reset the index to get the date back as a column\n",
    "        df_weekly.reset_index(inplace=True)\n",
    "        \n",
    "        # Add a column for the calendar week number based on the starting date of each week\n",
    "        df_weekly['calendar_week'] = df_weekly['date'].dt.isocalendar().week\n",
    "        \n",
    "        # Save the weekly data to the output folder\n",
    "        output_path = os.path.join(output_folder, filename)\n",
    "        df_weekly.to_csv(output_path, index=False)\n",
    "        \n",
    "        print(f'Saved weekly reduced data for {filename} to {output_path}')\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ee9d57177f618248"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
